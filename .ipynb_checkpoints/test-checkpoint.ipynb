{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac620138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T04:33:58.735797Z",
     "start_time": "2022-11-18T04:33:58.392222Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import NGIDS_dataset\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from models import *\n",
    "from NGIDS_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e66c6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-18T05:55:50.962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 6 4 8 3\n",
      "positive :  1770904\n",
      "negative :  30180\n",
      "1392578 1392578\n",
      "348145 348145\n",
      "60360 60360\n",
      "[1/150] loss : 0.14398910105228424  -- 15:00:11\n",
      "[2/150] loss : 0.13516217470169067  -- 15:01:39\n",
      "[3/150] loss : 0.13358892500400543  -- 15:03:07\n",
      "[4/150] loss : 0.13311177492141724  -- 15:04:35\n",
      "[5/150] loss : 0.13240163028240204  -- 15:06:04\n",
      "[6/150] loss : 0.13122397661209106  -- 15:07:32\n",
      "[7/150] loss : 0.1304744929075241  -- 15:09:01\n",
      "[8/150] loss : 0.1301903873682022  -- 15:10:30\n",
      "[9/150] loss : 0.1297498196363449  -- 15:11:59\n",
      "[10/150] loss : 0.1296214759349823  -- 15:13:27\n",
      "[11/150] loss : 0.1296757608652115  -- 15:14:56\n",
      "[12/150] loss : 0.12955741584300995  -- 15:16:25\n",
      "[13/150] loss : 0.12942969799041748  -- 15:17:53\n",
      "[14/150] loss : 0.12941664457321167  -- 15:19:22\n",
      "[15/150] loss : 0.1293758749961853  -- 15:20:50\n",
      "[16/150] loss : 0.12931804358959198  -- 15:22:19\n",
      "[17/150] loss : 0.12922553718090057  -- 15:23:47\n",
      "[18/150] loss : 0.1292513757944107  -- 15:25:16\n",
      "[19/150] loss : 0.12918533384799957  -- 15:26:45\n",
      "[20/150] loss : 0.12909871339797974  -- 15:28:13\n",
      "[21/150] loss : 0.12927180528640747  -- 15:29:42\n",
      "[22/150] loss : 0.12905733287334442  -- 15:31:12\n",
      "[23/150] loss : 0.12897653877735138  -- 15:32:40\n",
      "[24/150] loss : 0.12896014750003815  -- 15:34:09\n",
      "[25/150] loss : 0.1289854198694229  -- 15:35:38\n",
      "[26/150] loss : 0.1289552003145218  -- 15:37:07\n",
      "[27/150] loss : 0.12905532121658325  -- 15:38:36\n"
     ]
    }
   ],
   "source": [
    "import ngids_GRU\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "slide_window_size = 50\n",
    "max_epochs = 150\n",
    "hidden_size = [(8, 6, 4)]\n",
    "num_layers = 1\n",
    "early_stop = 5\n",
    "learning_rate = 0.001\n",
    "vector_size = [8, 10]\n",
    "window = [3, 5]\n",
    "\n",
    "for h, hh, l in hidden_size:\n",
    "    for v in vector_size :\n",
    "        for w in window :\n",
    "            print(h, hh, l, v, w)\n",
    "                \n",
    "            ngids_GRU.run(batch_size, slide_window_size, learning_rate, max_epochs, h, hh, l,early_stop, v, w, model_cont='CNN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deea7e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T05:50:23.363106Z",
     "start_time": "2022-11-18T05:50:23.109638Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'GRU_hidden_Decoder' on <module 'models' from 'C:\\\\Users\\\\AJOU\\\\Lee_JW\\\\Semi_supervised\\\\models.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7748/2029362701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'./result/repeat/s{slide_window_size}h{h}hh{hh}l{l}/v{v}w{w}/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"AutoEncoder.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mNGIDS_trainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"trainset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mNGIDS_testset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"testset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hyun\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hyun\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hyun\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[1;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'GRU_hidden_Decoder' on <module 'models' from 'C:\\\\Users\\\\AJOU\\\\Lee_JW\\\\Semi_supervised\\\\models.py'>"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "slide_window_size = 50\n",
    "hidden_size = [(8, 8, 6), (8, 6, 6), (8, 6, 4)]\n",
    "\n",
    "vector_size = [8, 10]\n",
    "window = [1, 3, 5]\n",
    "\n",
    "\n",
    "for h, hh, l in hidden_size :\n",
    "    for v in vector_size:\n",
    "        for w in window :\n",
    "            path = f'./result/repeat/s{slide_window_size}h{h}hh{hh}l{l}/v{v}w{w}/'\n",
    "\n",
    "            model = torch.load(path + \"AutoEncoder.model\")\n",
    "            NGIDS_trainset = torch.load(path + \"trainset\")\n",
    "            NGIDS_testset = torch.load(path + \"testset\")\n",
    "\n",
    "            model.eval() \n",
    "            train_loader = DataLoader(NGIDS_trainset, batch_size=batch_size, shuffle = True)\n",
    "            test_loader = DataLoader(NGIDS_testset, batch_size=len(NGIDS_testset), shuffle = True)\n",
    "\n",
    "            for i in [100, 150, 200] :\n",
    "\n",
    "                train_iterator = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True, desc=\"training\")\n",
    "\n",
    "                isfo = IsolationForest(n_estimators=i)\n",
    "\n",
    "                for idx, batch in train_iterator :\n",
    "\n",
    "                    output, _ = model(batch)\n",
    "                    output = output.detach().cpu().numpy()\n",
    "                    isfo.fit(output)\n",
    "\n",
    "                train_output = output    \n",
    "\n",
    "                tmp = iter(test_loader)\n",
    "                data = tmp.next()\n",
    "                _, label = data\n",
    "\n",
    "                output, _ = model(data)\n",
    "                output = output.detach().cpu().numpy()\n",
    "                test_output = output\n",
    "\n",
    "                y_pred = isfo.predict(output)\n",
    "                y_score_sample = isfo.score_samples(output)\n",
    "\n",
    "                for idx, j in enumerate(y_pred):\n",
    "                    if j == -1 :\n",
    "                        y_pred[idx] = 1\n",
    "                    else :\n",
    "                        y_pred[idx] = 0\n",
    "\n",
    "                fpr, tpr, thresholds = roc_curve(label, -y_score_sample)\n",
    "\n",
    "                print(\"accuracy score :\", accuracy_score(label, y_pred))\n",
    "                print(\"recall score :\", recall_score(label, y_pred))\n",
    "                print(\"precision score :\", precision_score(label, y_pred))\n",
    "                print(\"roc_auc :\", roc_auc_score(label, -y_score_sample))\n",
    "\n",
    "                fp = open(path + 'result.txt', 'w')\n",
    "\n",
    "                fp.write(f\"accuracy score : {accuracy_score(label, y_pred)}\\n\")\n",
    "                fp.write(f\"recall score : {recall_score(label, y_pred)}\\n\")\n",
    "                fp.write(f\"precision score : {precision_score(label, y_pred)}\\n\")\n",
    "                fp.write(f\"roc_auc : {roc_auc_score(label, -y_score_sample)}\")\n",
    "                fp.close\n",
    "\n",
    "                plt.plot(fpr, tpr, color=\"navy\")\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.savefig(path + 'auc.png')\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22345b4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:58:48.632978Z",
     "start_time": "2022-11-17T07:58:48.632978Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "slide_window_size = 50\n",
    "h = 8\n",
    "hh = 8\n",
    "l = 6\n",
    "vector_size = 8\n",
    "w = 3\n",
    "batch_size = 512\n",
    "\n",
    "path = f'./result/repeat/s{slide_window_size}h{h}hh{hh}l{l}/v{vector_size}w{w}/'\n",
    "\n",
    "model = torch.load(path + \"AutoEncoder.model\")\n",
    "NGIDS_trainset = torch.load(path + \"trainset\")\n",
    "NGIDS_testset = torch.load(path + \"testset\")\n",
    "\n",
    "model.eval() \n",
    "train_loader = DataLoader(NGIDS_trainset, batch_size=batch_size, shuffle = True)\n",
    "test_loader = DataLoader(NGIDS_testset, batch_size=len(NGIDS_testset), shuffle = True)\n",
    "train_iterator = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True, desc=\"training\")\n",
    "\n",
    "\n",
    "print(len(NGIDS_testset))\n",
    "\n",
    "isfo = IsolationForest(n_estimators=100)\n",
    "\n",
    "'''for idx, batch in train_iterator :\n",
    "    \n",
    "    output, _ = model(batch)\n",
    "    output = output.detach().cpu().numpy()\n",
    "    isfo.fit(output)'''\n",
    "\n",
    "#train_output = output    \n",
    "\n",
    "tmp = iter(test_loader)\n",
    "data = tmp.next()\n",
    "_, label = data\n",
    "\n",
    "output, _ = model(data)\n",
    "output = output.detach().cpu().numpy()\n",
    "test_output = output\n",
    "\n",
    "isfo.fit(output)\n",
    "\n",
    "y_pred = isfo.predict(output)\n",
    "y_score_sample = isfo.score_samples(output)\n",
    "\n",
    "for idx, j in enumerate(y_pred):\n",
    "    if j == -1 :\n",
    "        y_pred[idx] = 1\n",
    "    else :\n",
    "        y_pred[idx] = 0\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(label, -y_score_sample)\n",
    "\n",
    "print(\"accuracy score :\", accuracy_score(label, y_pred))\n",
    "print(\"recall score :\", recall_score(label, y_pred))\n",
    "print(\"precision score :\", precision_score(label, y_pred))\n",
    "print(\"roc_auc :\", roc_auc_score(label, -y_score_sample))\n",
    "\n",
    "fp = open(path + 'result.txt', 'w')\n",
    "\n",
    "fp.write(f\"accuracy score : {accuracy_score(label, y_pred)}\\n\")\n",
    "fp.write(f\"recall score : {recall_score(label, y_pred)}\\n\")\n",
    "fp.write(f\"precision score : {precision_score(label, y_pred)}\\n\")\n",
    "fp.write(f\"roc_auc : {roc_auc_score(label, -y_score_sample)}\")\n",
    "fp.close\n",
    "\n",
    "plt.plot(fpr, tpr, color=\"navy\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.savefig(path + 'auc.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tsne_input = test_output\n",
    "tsne_model = TSNE(n_components=2)\n",
    "z = tsne_model.fit_transform(tsne_input)\n",
    "\n",
    "positive = []\n",
    "negative = []\n",
    "\n",
    "for i in range(100):\n",
    "    if label[i] == 1 :\n",
    "        negative.append(z[i])\n",
    "    else :\n",
    "        positive.append(z[i])\n",
    "\n",
    "\n",
    "positive = np.array(positive)\n",
    "negative = np.array(negative)\n",
    "\n",
    "b2 = plt.scatter(positive[:, 0], positive[:, 1], c=\"green\", s=20, edgecolor=\"k\")\n",
    "c = plt.scatter(negative[:, 0], negative[:, 1], c=\"red\", s=20, edgecolor=\"k\")\n",
    "\n",
    "plt.savefig(path + \"tsne/png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d4f5e5333919c7baf0c3b886effb8804f3a4378a893d12116a2d10aaca08022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
