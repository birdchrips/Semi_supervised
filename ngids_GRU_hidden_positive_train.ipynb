{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T09:00:57.079524Z",
     "start_time": "2022-11-11T09:00:57.067601Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "NGIDS_path = './dataset/NGIDS_host_log_1-99.csv'\n",
    "\n",
    "device = torch.device('cuda') # GPU 사용\n",
    "batch_size = 256\n",
    "slide_window_size = 100\n",
    "learning_rate = 0.001\n",
    "max_epochs = 150\n",
    "hidden_size = 8\n",
    "hhidden_size = 6\n",
    "num_layers = 1\n",
    "early_stop = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T09:02:07.845863Z",
     "start_time": "2022-11-11T09:00:58.618980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive :  882954\n",
      "negative :  17588\n"
     ]
    }
   ],
   "source": [
    "NGIDS = pd.read_csv(NGIDS_path)\n",
    "        \n",
    "dropna_NGIDS = NGIDS.dropna(subset=['path', 'sys_call', 'label'])\n",
    "\n",
    "path = np.array(dropna_NGIDS['path'].to_list())\n",
    "syscall = np.array(dropna_NGIDS['sys_call'].to_list())\n",
    "label = np.array(dropna_NGIDS['label'].to_list())\n",
    "\n",
    "l = int(len(path) / slide_window_size)\n",
    "\n",
    "path = path[:l * slide_window_size].reshape(l, slide_window_size)\n",
    "syscall = syscall[:l * slide_window_size].reshape(l, slide_window_size)\n",
    "label = label[:l * slide_window_size].reshape(l, slide_window_size)\n",
    "\n",
    "label = np.max(label, axis = 1)\n",
    "#label = label[:, -1]\n",
    "\n",
    "positive_path = []\n",
    "positive_syscall = []\n",
    "\n",
    "negative_path = []\n",
    "negative_syscall = []\n",
    "\n",
    "for i in range(l) :\n",
    "    if label[i] == 1 :\n",
    "        negative_path.append(path[i])\n",
    "        negative_syscall.append(syscall[i])\n",
    "    else :\n",
    "        positive_path.append(path[i])\n",
    "        positive_syscall.append(syscall[i])\n",
    "\n",
    "\n",
    "positive_len = len(positive_path)\n",
    "negative_len = len(negative_path)\n",
    "\n",
    "print(\"positive : \", positive_len)\n",
    "print(\"negative : \", negative_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T09:02:09.687803Z",
     "start_time": "2022-11-11T09:02:09.035538Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_vali, y_train, y_vali = train_test_split(\n",
    "    list(zip(positive_path[:positive_len - negative_len - 1], positive_syscall[:positive_len - negative_len - 1]))\n",
    "    , [0 for i in range(positive_len - negative_len - 1)], test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = list(zip(positive_path[positive_len - negative_len : positive_len] + negative_path, \n",
    "                positive_syscall[positive_len - negative_len : positive_len] + negative_syscall))\n",
    "y_test = [ 0 for i in range(negative_len)] + [ 1 for i in range(negative_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T09:02:09.703269Z",
     "start_time": "2022-11-11T09:02:09.687803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692292 692292\n",
      "173073 173073\n",
      "35176 35176\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_vali), len(y_vali))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T09:02:09.920989Z",
     "start_time": "2022-11-11T09:02:09.703269Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def save_path(vector_size, window, data_name=\"NGIDS_path_w2v\"):\n",
    "    return \"./dataset/PathSystem/\" + f\"vectorsize{vector_size}_window{window}_\" + data_name\n",
    "\n",
    "def save_sys(vector_size, window, data_name = \"NGIDS_vector\"):\n",
    "    return \"./dataset/PathSystem/\" + f\"vectorsize{vector_size}_window{window}_\" + data_name\n",
    "\n",
    "\n",
    "vector_size = 10\n",
    "window = 3\n",
    "input_size = vector_size\n",
    "\n",
    "NGIDS_sys_model = gensim.models.Word2Vec.load(save_sys(vector_size, window))\n",
    "NGIDS_path_model = gensim.models.Word2Vec.load(save_path(vector_size, window, \"NGIDS_vector\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-11T09:01:03.825Z"
    }
   },
   "outputs": [],
   "source": [
    "p2i = NGIDS_path_model.wv.key_to_index\n",
    "s2i = NGIDS_sys_model.wv.key_to_index\n",
    "\n",
    "NGIDS_dataset = NGIDS_Dataset(X_train, y_train, p2i, s2i, slide_window_size)\n",
    "train_loader = DataLoader(NGIDS_dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "NGIDS_valiset = NGIDS_Dataset(X_vali, y_vali, p2i, s2i, slide_window_size)\n",
    "vali_loader = DataLoader(NGIDS_valiset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "NGIDS_testset = NGIDS_Dataset(X_test, y_test, p2i, s2i, slide_window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-11T09:01:04.153Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hhidden_size, num_layers, dropout_p=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.gru1 = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.gru2 = nn.GRU(hidden_size, hhidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        batch, _ = self.gru1(batch)\n",
    "        batch = self.dropout(batch)\n",
    "        outputs, hidden = self.gru2(batch)\n",
    "        return outputs, hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hhidden_size, num_layers, dropout_p=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.gru1 = nn.GRU(hhidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.gru2 = nn.GRU(hidden_size, input_size, batch_first=True)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch, _ = self.gru1(batch)\n",
    "        batch = self.dropout(batch)\n",
    "        output, hidden = self.gru2(batch)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-11T09:01:04.898Z"
    }
   },
   "outputs": [],
   "source": [
    "class GRU_AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hhidden_size, num_layers, path_vecs, sys_vecs):\n",
    "        super(GRU_AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.path_emb = nn.Embedding.from_pretrained(torch.tensor(path_vecs, dtype=torch.float).cuda(), freeze=True)\n",
    "        self.sys_emb = nn.Embedding.from_pretrained(torch.tensor(sys_vecs, dtype=torch.float).cuda(), freeze=True)\n",
    "\n",
    "        self.encoder = Encoder(input_size=input_size, hidden_size=hidden_size, hhidden_size=hhidden_size, num_layers=num_layers)\n",
    "        self.reconstruct_decoder = Decoder(input_size=input_size, hidden_size=hidden_size, hhidden_size=hhidden_size, num_layers=num_layers)\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch, _  = batch\n",
    "\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        batch_size, sequence_length, _ = batch.size()\n",
    "        vector_size = self.input_size\n",
    "        \n",
    "        path_batch = self.path_emb(batch[:,:,0])\n",
    "        sys_batch = self.sys_emb(batch[:,:,1])\n",
    "\n",
    "        batch = path_batch + sys_batch\n",
    "        batch = batch.reshape(batch_size, sequence_length, vector_size)\n",
    "        \n",
    "        outputs, encoder_hidden = self.encoder(batch)\n",
    "        outputs, decoder_hidden = self.reconstruct_decoder(outputs)\n",
    "        \n",
    "        reconstruct_loss = self.criterion(outputs, batch)\n",
    "\n",
    "        batch = batch.to(\"cpu\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return outputs, reconstruct_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-11T09:01:05.865Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(model, train_loader):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    epochs = range(max_epochs)\n",
    "    \n",
    "    loss_list = []\n",
    "    min_loss = 1\n",
    "    count = 0\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for i, batch_data in enumerate(train_loader):\n",
    "\n",
    "            _, reconstruct_loss = model(batch_data)\n",
    "\n",
    "            loss = reconstruct_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()        \n",
    "        epoch_loss = 0\n",
    "\n",
    "        with torch.no_grad() :\n",
    "            for i, batch_data in enumerate(vali_loader):\n",
    "                _, reconstruct_loss = model(batch_data)\n",
    "                epoch_loss = epoch_loss + reconstruct_loss\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(vali_loader)\n",
    "            loss_list.append(epoch_loss)\n",
    "\n",
    "            print(f\"[{epoch + 1}/{max_epochs}] loss : {epoch_loss}  -- \" + \n",
    "                    f\"{time.strftime('%H:%M:%S', time.localtime(time.time()))}\")\n",
    "\n",
    "        if min_loss > epoch_loss :\n",
    "            min_loss = epoch_loss\n",
    "            save_model = model\n",
    "            count = 0\n",
    "        else :\n",
    "            count = count + 1\n",
    "\n",
    "        #torch.save(model, f\"GRU_Positive_training_Auto_encoder_epoch{epoch}.model\")\n",
    "\n",
    "        if count >= early_stop :\n",
    "            break\n",
    "            \n",
    "    return save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/150] loss : 0.2257036566734314  -- 15:10:19\n",
      "[2/150] loss : 0.22168932855129242  -- 15:10:58\n",
      "[3/150] loss : 0.220005065202713  -- 15:11:38\n",
      "[4/150] loss : 0.21732881665229797  -- 15:12:18\n",
      "[5/150] loss : 0.2165941745042801  -- 15:12:58\n",
      "[6/150] loss : 0.216220423579216  -- 15:13:38\n",
      "[7/150] loss : 0.2159835547208786  -- 15:14:18\n",
      "[8/150] loss : 0.2157013714313507  -- 15:14:58\n",
      "[9/150] loss : 0.21545495092868805  -- 15:15:38\n",
      "[10/150] loss : 0.21528199315071106  -- 15:16:18\n",
      "[11/150] loss : 0.21521101891994476  -- 15:16:59\n",
      "[12/150] loss : 0.215177521109581  -- 15:17:39\n",
      "[13/150] loss : 0.21505936980247498  -- 15:18:19\n",
      "[14/150] loss : 0.21498778462409973  -- 15:19:00\n",
      "[15/150] loss : 0.21482466161251068  -- 15:19:40\n",
      "[16/150] loss : 0.21485555171966553  -- 15:20:21\n",
      "[17/150] loss : 0.21463866531848907  -- 15:21:01\n",
      "[18/150] loss : 0.21473044157028198  -- 15:21:41\n",
      "[19/150] loss : 0.2147301733493805  -- 15:22:22\n",
      "[20/150] loss : 0.21464236080646515  -- 15:23:02\n",
      "[21/150] loss : 0.21438612043857574  -- 15:23:43\n",
      "[22/150] loss : 0.21440757811069489  -- 15:24:23\n",
      "[23/150] loss : 0.21438322961330414  -- 15:25:04\n",
      "[24/150] loss : 0.21431811153888702  -- 15:25:44\n",
      "[25/150] loss : 0.21429426968097687  -- 15:26:25\n",
      "[26/150] loss : 0.21455591917037964  -- 15:27:05\n",
      "[27/150] loss : 0.21420811116695404  -- 15:27:46\n",
      "[28/150] loss : 0.21413689851760864  -- 15:28:26\n",
      "[29/150] loss : 0.21529823541641235  -- 15:29:07\n",
      "[30/150] loss : 0.2141699641942978  -- 15:29:47\n",
      "[31/150] loss : 0.21406719088554382  -- 15:30:27\n",
      "[32/150] loss : 0.2142494171857834  -- 15:31:07\n",
      "[33/150] loss : 0.21393531560897827  -- 15:31:48\n",
      "[34/150] loss : 0.21404393017292023  -- 15:32:28\n",
      "[35/150] loss : 0.2137802690267563  -- 15:33:08\n",
      "[36/150] loss : 0.21371473371982574  -- 15:33:49\n",
      "[37/150] loss : 0.21393539011478424  -- 15:34:29\n",
      "[38/150] loss : 0.21368247270584106  -- 15:35:09\n",
      "[39/150] loss : 0.21341876685619354  -- 15:35:49\n",
      "[40/150] loss : 0.21325531601905823  -- 15:36:29\n",
      "[41/150] loss : 0.2133515328168869  -- 15:37:09\n",
      "[42/150] loss : 0.2133939117193222  -- 15:37:49\n",
      "[43/150] loss : 0.21311362087726593  -- 15:38:29\n",
      "[44/150] loss : 0.2132510542869568  -- 15:39:09\n",
      "[45/150] loss : 0.21309290826320648  -- 15:39:49\n",
      "[46/150] loss : 0.21316929161548615  -- 15:40:29\n",
      "[47/150] loss : 0.21324583888053894  -- 15:41:09\n",
      "[48/150] loss : 0.21310728788375854  -- 15:41:49\n",
      "[49/150] loss : 0.21308957040309906  -- 15:42:29\n",
      "[50/150] loss : 0.21313577890396118  -- 15:43:09\n",
      "[51/150] loss : 0.2130945473909378  -- 15:43:50\n",
      "[52/150] loss : 0.21319109201431274  -- 15:44:29\n",
      "[53/150] loss : 0.21354807913303375  -- 15:45:09\n",
      "[54/150] loss : 0.2134813368320465  -- 15:45:50\n",
      "[55/150] loss : 0.21291282773017883  -- 15:46:30\n",
      "[56/150] loss : 0.2129395753145218  -- 15:47:10\n",
      "[57/150] loss : 0.2128627449274063  -- 15:47:50\n",
      "[58/150] loss : 0.21286214888095856  -- 15:48:30\n",
      "[59/150] loss : 0.21285703778266907  -- 15:49:10\n",
      "[60/150] loss : 0.2128136307001114  -- 15:49:50\n",
      "[61/150] loss : 0.21278513967990875  -- 15:50:31\n",
      "[62/150] loss : 0.21282818913459778  -- 15:51:11\n",
      "[63/150] loss : 0.21291086077690125  -- 15:51:51\n",
      "[64/150] loss : 0.21278196573257446  -- 15:52:31\n",
      "[65/150] loss : 0.2129056304693222  -- 15:53:10\n",
      "[66/150] loss : 0.21270668506622314  -- 15:53:50\n",
      "[67/150] loss : 0.21279264986515045  -- 15:54:31\n",
      "[68/150] loss : 0.2126116156578064  -- 15:55:11\n",
      "[69/150] loss : 0.21260318160057068  -- 15:55:51\n",
      "[70/150] loss : 0.21257586777210236  -- 15:56:30\n",
      "[71/150] loss : 0.21256200969219208  -- 15:57:09\n",
      "[72/150] loss : 0.21280241012573242  -- 15:57:49\n",
      "[73/150] loss : 0.2125617116689682  -- 15:58:29\n",
      "[74/150] loss : 0.2125663161277771  -- 15:59:09\n",
      "[75/150] loss : 0.21261896193027496  -- 15:59:49\n",
      "[76/150] loss : 0.2128613144159317  -- 16:00:28\n",
      "[77/150] loss : 0.21250194311141968  -- 16:01:07\n",
      "[78/150] loss : 0.21261747181415558  -- 16:01:46\n",
      "[79/150] loss : 0.2124917060136795  -- 16:02:25\n",
      "[80/150] loss : 0.22054728865623474  -- 16:03:04\n",
      "[81/150] loss : 0.21466457843780518  -- 16:03:44\n",
      "[82/150] loss : 0.21305015683174133  -- 16:04:23\n",
      "[83/150] loss : 0.21268188953399658  -- 16:05:02\n",
      "[84/150] loss : 0.21254681050777435  -- 16:05:41\n",
      "[85/150] loss : 0.2125052809715271  -- 16:06:21\n",
      "[86/150] loss : 0.21278585493564606  -- 16:07:00\n",
      "[87/150] loss : 0.21245025098323822  -- 16:07:39\n",
      "[88/150] loss : 0.21240921318531036  -- 16:08:18\n",
      "[89/150] loss : 0.21239276230335236  -- 16:08:58\n",
      "[90/150] loss : 0.21395905315876007  -- 16:09:38\n",
      "[91/150] loss : 0.21253764629364014  -- 16:10:18\n",
      "[92/150] loss : 0.2124406099319458  -- 16:10:58\n",
      "[93/150] loss : 0.2124147117137909  -- 16:11:37\n",
      "[94/150] loss : 0.2123749703168869  -- 16:12:15\n",
      "[95/150] loss : 0.212325319647789  -- 16:12:54\n",
      "[96/150] loss : 0.21238547563552856  -- 16:13:33\n",
      "[97/150] loss : 0.2124449759721756  -- 16:14:11\n",
      "[98/150] loss : 0.21238480508327484  -- 16:14:50\n",
      "[99/150] loss : 0.2125038057565689  -- 16:15:29\n",
      "[100/150] loss : 0.21247702836990356  -- 16:16:07\n",
      "[101/150] loss : 0.25418606400489807  -- 16:16:46\n",
      "[102/150] loss : 0.24111595749855042  -- 16:17:25\n",
      "[103/150] loss : 0.2193688154220581  -- 16:18:03\n",
      "[104/150] loss : 0.21532878279685974  -- 16:18:42\n",
      "[105/150] loss : 0.28959718346595764  -- 16:19:21\n",
      "[106/150] loss : 0.28921765089035034  -- 16:19:59\n",
      "[107/150] loss : 0.28997504711151123  -- 16:20:38\n",
      "[108/150] loss : 0.30715370178222656  -- 16:21:16\n",
      "[109/150] loss : 0.29724735021591187  -- 16:21:55\n",
      "[110/150] loss : 0.29562675952911377  -- 16:22:34\n",
      "[111/150] loss : 0.2909800708293915  -- 16:23:12\n",
      "[112/150] loss : 0.2736853063106537  -- 16:23:51\n",
      "[113/150] loss : 0.2906796634197235  -- 16:24:30\n",
      "[114/150] loss : 0.29784178733825684  -- 16:25:08\n",
      "[115/150] loss : 0.2692623436450958  -- 16:25:47\n"
     ]
    }
   ],
   "source": [
    "model = GRU_AutoEncoder(input_size, hidden_size, num_layers, hhidden_size, NGIDS_path_model.wv.vectors, NGIDS_sys_model.wv.vectors)\n",
    "model.to(device)\n",
    "\n",
    "model = run(model, train_loader)\n",
    "\n",
    "torch.save(model, \"positive_trainingAutoEncoder.model\")\n",
    "\n",
    "print(\"learning finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-11T09:01:08.246Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-11T09:01:08.849Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_result(isfo, X_test, y_test):\n",
    "    \n",
    "    NGIDS_testset = NGIDS_Dataset(X_test, y_test, p2i, s2i, slide_window_size)\n",
    "    test_loader = DataLoader(NGIDS_testset, batch_size=len(NGIDS_testset), shuffle = True)\n",
    "    \n",
    "    tmp = iter(test_loader)\n",
    "    data = tmp.next()\n",
    "    _, label = data\n",
    "    \n",
    "    output, _ = model(data)\n",
    "    output = output.detach().cpu().numpy()\n",
    "\n",
    "    y_pred = isfo.predict(output[:, -1, :])\n",
    "    y_score_sample = isfo.score_samples(output[:, -1, :])\n",
    "\n",
    "    for idx, j in enumerate(y_pred):\n",
    "        if j == -1 :\n",
    "            y_pred[idx] = 1\n",
    "        else :\n",
    "            y_pred[idx] = 0\n",
    "    \n",
    "\n",
    "    print(\"accuracy score :\", accuracy_score(label, y_pred))\n",
    "    print(\"recall score :\", recall_score(label, y_pred))\n",
    "    print(\"precision score :\", precision_score(label, y_pred))\n",
    "    print(\"roc_auc :\", roc_auc_score(label, -y_score_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-11T09:01:09.465Z"
    }
   },
   "outputs": [],
   "source": [
    "def ISFO_result(model, n_estimators = 100, max_samples=\"auto\", contamination = 'auto', max_features = 1.0):\n",
    "    isfo = IsolationForest()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    train_loader = DataLoader(NGIDS_dataset, batch_size=batch_size, shuffle = True)\n",
    "    train_iterator = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True, desc=\"training\")\n",
    "\n",
    "    for i, batch in train_iterator :\n",
    "        \n",
    "        output, _ = model(batch)\n",
    "        output = output.detach().cpu().numpy()\n",
    "        isfo.fit(output[:, -1, :])\n",
    "    \n",
    "    return isfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-11T09:01:09.986Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"positive_trainingAutoEncoder.model\")\n",
    "\n",
    "isfo = IsolationForest(n_estimators=100)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "train_loader = DataLoader(NGIDS_dataset, batch_size=batch_size, shuffle = True)\n",
    "train_iterator = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True, desc=\"training\")\n",
    "\n",
    "for i, batch in train_iterator :\n",
    "    \n",
    "    output, _ = model(batch)\n",
    "    output = output.detach().cpu().numpy()\n",
    "    isfo.fit(output[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.6217591539686149\n",
      "recall score : 0.37275415055719807\n",
      "precision score : 0.7425529505040208\n",
      "roc_auc : 0.7193848158406431\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NGIDS_testset = NGIDS_Dataset(X_test, y_test, p2i, s2i, slide_window_size)\n",
    "test_loader = DataLoader(NGIDS_testset, batch_size=len(NGIDS_testset), shuffle = True)\n",
    "\n",
    "tmp = iter(test_loader)\n",
    "data = tmp.next()\n",
    "_, label = data\n",
    "\n",
    "output, _ = model(data)\n",
    "output = output.detach().cpu().numpy()\n",
    "\n",
    "y_pred = isfo.predict(output[:, -1, :])\n",
    "y_score_sample = isfo.score_samples(output[:, -1, :])\n",
    "\n",
    "for idx, j in enumerate(y_pred):\n",
    "    if j == -1 :\n",
    "        y_pred[idx] = 1\n",
    "    else :\n",
    "        y_pred[idx] = 0\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(label, -y_score_sample)\n",
    "\n",
    "print(\"accuracy score :\", accuracy_score(label, y_pred))\n",
    "print(\"recall score :\", recall_score(label, y_pred))\n",
    "print(\"precision score :\", precision_score(label, y_pred))\n",
    "print(\"roc_auc :\", roc_auc_score(label, -y_score_sample))\n",
    "\n",
    "plt.plot(fpr, tpr, color=\"navy\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d4f5e5333919c7baf0c3b886effb8804f3a4378a893d12116a2d10aaca08022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
